{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPzez254KSBhScrE2IeToN0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/govindakolli/Transformers/blob/main/01_Attention_in_Transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Self Attention"
      ],
      "metadata": {
        "id": "OJ9IgUiW1Yjt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Self Attention code"
      ],
      "metadata": {
        "id": "wE-w3Umz6Oq1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "m5t_hHPqtWDh"
      },
      "outputs": [],
      "source": [
        "import torch # Hepls in creating tensors and also provides helper functions\n",
        "import torch.nn as nn # Gives us nn.Module() and nn.Linear()\n",
        "import torch.nn.functional as F # This gives us Softmac()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttention(nn.Module):\n",
        "  def __init__(self, d_model = 2,\n",
        "               row_dim =0,\n",
        "               col_dim = 1 ):\n",
        "        # d_model = the number of embedding values per token.Because we want to be able to do the math by hand, we've the default value for\n",
        "        #           d_model=2. However, in \"Attention Is All You Need\" d_model=512\n",
        "        # row_dim, col_dim = the indices we should use to access rows or columns\n",
        "\n",
        "    super().__init__()\n",
        "\n",
        "        # Initialize the Weights (W) that we'll use to create the query (q), key (k) and value (v) for each token\n",
        "        # NOTE: A lot of implementations include bias terms when creating the the queries, keys, and values, but the original manuscript\n",
        "        #       that described Attention, \"Attention Is All You Need\" did not, so we won't either\n",
        "\n",
        "    self.W_q = nn.Linear(in_features = d_model, out_features = d_model, bias = False)\n",
        "    self.W_k = nn.Linear(in_features = d_model, out_features = d_model, bias = False)\n",
        "    self.W_v = nn.Linear(in_features = d_model, out_features = d_model, bias = False)\n",
        "\n",
        "    self.row_dim = row_dim\n",
        "    self.col_dim = col_dim\n",
        "\n",
        "  def forward(self, token_encodings):\n",
        "     # Create the query, key and values using the encoding numbers associated with each token (token encodings)\n",
        "\n",
        "     q = self.W_q(token_encodings)\n",
        "     k = self.W_k(token_encodings)\n",
        "     v = self.W_v(token_encodings)\n",
        "\n",
        "     # Compute unscaled similarity scores ( q * k^T )\n",
        "     unscaled_similarity_scores = torch.mm(q, k.transpose(dim0 = self.row_dim, dim1 = self.col_dim))\n",
        "\n",
        "     # Scale the similarities by dividing by sqrt(k.col_dim)\n",
        "     scaled_similarity_scores = unscaled_similarity_scores / torch.sqrt(torch.tensor(k.size(self.col_dim)))\n",
        "\n",
        "     # Apply softmax to determine what percent of each tokens' value to use in the final attention values.\n",
        "     attention_percents = F.softmax(scaled_similarity_scores, dim = self.col_dim)\n",
        "\n",
        "     # Scale the values by their associated percentages and add them up.\n",
        "     attention_scores = torch.matmul(attention_percents, v)\n",
        "\n",
        "     return attention_scores\n",
        "\n"
      ],
      "metadata": {
        "id": "buMq1vtFuhGS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate Self Attention"
      ],
      "metadata": {
        "id": "BE0sLwT46WC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a matrix of token encodings...\n",
        "encodings_matrix = torch.tensor([[1.16, 0.23],\n",
        "                                 [0.57, 1.36],\n",
        "                                 [4.41, -2.16]])\n",
        "\n",
        "# Set the seed for random number generator\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Create a basic self attention object\n",
        "selfAttention = SelfAttention(d_model=2,\n",
        "                               row_dim=0,\n",
        "                               col_dim=1)\n",
        "\n",
        "\n",
        "# Calculate the self attention scores\n",
        "selfAttention(encodings_matrix)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J949Ubkc6Uq1",
        "outputId": "435da8e7-30ed-43b6-d7b9-ed7f9636cbe8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0100, 1.0641],\n",
              "        [0.2040, 0.7057],\n",
              "        [3.4989, 2.2427]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Print out Weights and Verify calculations"
      ],
      "metadata": {
        "id": "ihRM6L4W8sAn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out the weight matrix that creates the queries\n",
        "selfAttention.W_q.weight.transpose(0, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoL8sE1C7VUV",
        "outputId": "28031a4a-efac-4490-c93c-8e86ed8b9d8e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.5406, -0.1657],\n",
              "        [ 0.5869,  0.6496]], grad_fn=<TransposeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out the weight matrix that creates the keys\n",
        "selfAttention.W_k.weight.transpose(0, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TF6fDt1j-EWt",
        "outputId": "d04f4e7a-eace-4756-cb71-8b533e56004f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1549, -0.3443],\n",
              "        [ 0.1427,  0.4153]], grad_fn=<TransposeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out the weight matrix that creates the values\n",
        "selfAttention.W_v.weight.transpose(0, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_xVaKbP_Ufh",
        "outputId": "e3fe12f1-99a6-4bc3-af83-19f183c69032"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.6233,  0.6146],\n",
              "        [-0.5188,  0.1323]], grad_fn=<TransposeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LIUOrmcF_XxO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the queries\n",
        "selfAttention.W_q(encodings_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JR9rgfl_au1",
        "outputId": "acdb6ee7-e697-4ee1-f88d-2dd2a3a86841"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.7621, -0.0428],\n",
              "        [ 1.1063,  0.7890],\n",
              "        [ 1.1164, -2.1336]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the keys\n",
        "selfAttention.W_k(encodings_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_h-hZnk1_daE",
        "outputId": "cc6a3070-87ee-4fcc-8b5a-cd27c3c110f8"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1469, -0.3038],\n",
              "        [ 0.1057,  0.3685],\n",
              "        [-0.9914, -2.4152]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the values\n",
        "selfAttention.W_v(encodings_matrix)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnQ_3ByD_eqC",
        "outputId": "e7beb2e1-c251-4d6a-8c85-f6b52b2091ab"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.6038,  0.7434],\n",
              "        [-0.3502,  0.5303],\n",
              "        [ 3.8695,  2.4246]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "q = selfAttention.W_q(encodings_matrix)\n",
        "q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2VjNwAx_isn",
        "outputId": "a9a38963-06b0-4d07-c5ed-45b907aaf052"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.7621, -0.0428],\n",
              "        [ 1.1063,  0.7890],\n",
              "        [ 1.1164, -2.1336]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k = selfAttention.W_k(encodings_matrix)\n",
        "k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yf5M6hHQ_lkl",
        "outputId": "91cd4443-87bc-4b55-da98-b3a6ff134870"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1469, -0.3038],\n",
              "        [ 0.1057,  0.3685],\n",
              "        [-0.9914, -2.4152]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sims = torch.matmul(q, k.transpose(dim0=0, dim1=1))\n",
        "sims"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pnrzOpJ_oBw",
        "outputId": "c52234c3-1a3a-47e5-c484-d21122317be2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0990,  0.0648, -0.6523],\n",
              "        [-0.4022,  0.4078, -3.0024],\n",
              "        [ 0.4842, -0.6683,  4.0461]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_sims = sims / (torch.tensor(2)**0.5)\n",
        "scaled_sims"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvEB145y_q3y",
        "outputId": "60af65c7-a7fd-407d-9802-e40c1301926f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0700,  0.0458, -0.4612],\n",
              "        [-0.2844,  0.2883, -2.1230],\n",
              "        [ 0.3424, -0.4725,  2.8610]], grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_percents = F.softmax(scaled_sims, dim=1)\n",
        "attention_percents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-tlqcuJ6_uFC",
        "outputId": "2d4e921b-8583-4673-ff4a-d578d6341320"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3573, 0.4011, 0.2416],\n",
              "        [0.3410, 0.6047, 0.0542],\n",
              "        [0.0722, 0.0320, 0.8959]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.matmul(attention_percents, selfAttention.W_v(encodings_matrix))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5skmBxtI_wup",
        "outputId": "233b3fe7-a766-4aa3-af9a-9856d8d1015c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0100, 1.0641],\n",
              "        [0.2040, 0.7057],\n",
              "        [3.4989, 2.2427]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Masked Self-Attention"
      ],
      "metadata": {
        "id": "h2Y3jJaakx5_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Masked Self-Attention code"
      ],
      "metadata": {
        "id": "mFfR4kyaks9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MaskedSelfAttention(nn.Module):\n",
        "  def __init__(self, d_model = 2, row_dim = 0, col_dim = 1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.W_q = nn.Linear(in_features = d_model, out_features = d_model, bias = False)\n",
        "    self.W_k = nn.Linear(in_features = d_model, out_features = d_model, bias = False)\n",
        "    self.W_v = nn.Linear(in_features = d_model, out_features = d_model, bias = False)\n",
        "\n",
        "    self.row_dim = row_dim\n",
        "    self.col_dim = col_dim\n",
        "\n",
        "  def forward(self, token_encodings, mask = None):\n",
        "    q = self.W_q(token_encodings)\n",
        "    k = self.W_k(token_encodings)\n",
        "    v = self.W_v(token_encodings)\n",
        "\n",
        "    # Compute unscaled similarity scores ( q * k^T )\n",
        "    unscaled_similarity_scores = torch.mm(q, k.transpose(dim0 = self.row_dim, dim1 = self.col_dim))\n",
        "\n",
        "    # Scale the similarities by dividing by sqrt(k.col_dim)\n",
        "    scaled_similarity_scores = unscaled_similarity_scores / torch.sqrt(torch.tensor(k.size(self.col_dim)))\n",
        "\n",
        "    if mask is not None:\n",
        "      # Here we are masking out things we don't want to pay attention to\n",
        "      # We replace values we wanted masked out with a very small negative number so that the SoftMax() function\n",
        "      # will give all masked elements an output value (or \"probability\") of 0.\n",
        "      scaled_similarity_scores = scaled_similarity_scores.masked_fill(mask=mask, value=-1e9) # I've also seen -1e20 and -9e15 used in masking\n",
        "\n",
        "    # Apply softmax to determine what percent of each tokens' value to use in the final attention values.\n",
        "    attention_percents = F.softmax(scaled_similarity_scores, dim = self.col_dim)\n",
        "\n",
        "    # Scale the values by their associated percentages and add them up.\n",
        "    attention_scores = torch.matmul(attention_percents, v)\n",
        "\n",
        "    return attention_scores\n"
      ],
      "metadata": {
        "id": "PbWLYG0O_z5N"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate Masked Self-Attention"
      ],
      "metadata": {
        "id": "Z7y1NLKup7Xh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create token Encodings\n",
        "encodings_matrix = torch.tensor([[1.16, 0.23],\n",
        "                                 [0.57, 1.36],\n",
        "                                 [4.41, -2.16]])\n",
        "\n",
        "# Set a manual seed for random number generator\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Create mask self attention object\n",
        "maskedSelfAttention = MaskedSelfAttention(d_model = 2,\n",
        "                                          row_dim = 0,\n",
        "                                          col_dim = 1)\n",
        "\n",
        "# Create a mask so that we don't use tokens that come after a token of interest\n",
        "mask = torch.tril(torch.ones(3,3)) # tril makes a lower triangle\n",
        "mask = mask == 0\n",
        "mask\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvlhejnrpwy5",
        "outputId": "f6bc87f6-79da-4cd7-da8e-72fae4d8218c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False,  True,  True],\n",
              "        [False, False,  True],\n",
              "        [False, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate Masked Self Attention\n",
        "maskedSelfAttention(encodings_matrix, mask)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-zgye1nrXdF",
        "outputId": "012cf158-802a-479a-86f5-5e529fa4f584"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.6038,  0.7434],\n",
              "        [-0.0062,  0.6072],\n",
              "        [ 3.4989,  2.2427]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Print out Weights and verify calculations"
      ],
      "metadata": {
        "id": "2VR1LrZgrp-n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## print out the weight matrix that creates the queries\n",
        "maskedSelfAttention.W_q.weight.transpose(0, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixuSYvZtrmdz",
        "outputId": "09db6b7a-e785-40d3-9faf-836afbbd0f2e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.5406, -0.1657],\n",
              "        [ 0.5869,  0.6496]], grad_fn=<TransposeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## print out the weight matrix that creates the keys\n",
        "maskedSelfAttention.W_k.weight.transpose(0, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9veipLN2r_TC",
        "outputId": "95130cf4-e214-450c-a320-4997a5c06bc9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1549, -0.3443],\n",
              "        [ 0.1427,  0.4153]], grad_fn=<TransposeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## print out the weight matrix that creates the values\n",
        "maskedSelfAttention.W_v.weight.transpose(0, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3pDlR0PsCLW",
        "outputId": "a9f20b6c-65e8-470f-d708-c60c2a046594"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.6233,  0.6146],\n",
              "        [-0.5188,  0.1323]], grad_fn=<TransposeBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the queries\n",
        "q = maskedSelfAttention.W_q(encodings_matrix)\n",
        "q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9wR9vZt4sKUP",
        "outputId": "3413291b-6872-4672-c86f-a25b88f3cba2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.7621, -0.0428],\n",
              "        [ 1.1063,  0.7890],\n",
              "        [ 1.1164, -2.1336]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the keys\n",
        "k = maskedSelfAttention.W_k(encodings_matrix)\n",
        "k"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hP8pimrsT-d",
        "outputId": "cb3c53d1-bff2-434f-dfc7-d6896c1369ee"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1469, -0.3038],\n",
              "        [ 0.1057,  0.3685],\n",
              "        [-0.9914, -2.4152]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sims = torch.matmul(q, k.transpose(dim0=0, dim1=1))\n",
        "sims"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XvIIyMEsrLb",
        "outputId": "f148d17d-3795-4305-da63-9e0d36ead16e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0990,  0.0648, -0.6523],\n",
              "        [-0.4022,  0.4078, -3.0024],\n",
              "        [ 0.4842, -0.6683,  4.0461]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaled_sims = sims / (torch.tensor(2)**0.5)\n",
        "scaled_sims"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1YqwH3usvbv",
        "outputId": "a9e82484-dd03-426e-e03a-dffdaed550a8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0700,  0.0458, -0.4612],\n",
              "        [-0.2844,  0.2883, -2.1230],\n",
              "        [ 0.3424, -0.4725,  2.8610]], grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masked_scaled_sims = scaled_sims.masked_fill(mask=mask, value=-1e9)\n",
        "masked_scaled_sims"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQ_qZQT0szoR",
        "outputId": "e2d456ac-9420-4ebe-ca49-26ae9d3f6465"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-6.9975e-02, -1.0000e+09, -1.0000e+09],\n",
              "        [-2.8442e-01,  2.8833e-01, -1.0000e+09],\n",
              "        [ 3.4241e-01, -4.7253e-01,  2.8610e+00]],\n",
              "       grad_fn=<MaskedFillBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_percents = F.softmax(masked_scaled_sims, dim=1)\n",
        "attention_percents"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqgehVyEs7uV",
        "outputId": "7af39bd1-ab51-4840-c20a-32809373295e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0000, 0.0000, 0.0000],\n",
              "        [0.3606, 0.6394, 0.0000],\n",
              "        [0.0722, 0.0320, 0.8959]], grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate the values\n",
        "v = maskedSelfAttention.W_v(encodings_matrix)\n",
        "v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hp6k_ZJEsfzC",
        "outputId": "1be6aef2-dfed-4707-f3ca-b38553e6158c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.6038,  0.7434],\n",
              "        [-0.3502,  0.5303],\n",
              "        [ 3.8695,  2.4246]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.matmul(attention_percents, v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjhwR2GeslaC",
        "outputId": "c07ae3f8-723c-4644-e370-4bc88c713fda"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.6038,  0.7434],\n",
              "        [-0.0062,  0.6072],\n",
              "        [ 3.4989,  2.2427]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attention"
      ],
      "metadata": {
        "id": "MlCev4-yrmNq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code Attention"
      ],
      "metadata": {
        "id": "_d6OZ3HcrqI9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "  def __init__(self, d_model = 2, row_dim = 0, col_dim = 1):\n",
        "    super().__init__()\n",
        "\n",
        "    self.W_q = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
        "    self.W_k = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
        "    self.W_v = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n",
        "\n",
        "    self.row_dim = row_dim\n",
        "    self.col_dim = col_dim\n",
        "\n",
        "  # The only change from SelfAttention and attention is that now we expect 3 sets of encodings to be passed in...\n",
        "  def forward(self, encodings_for_Q, encodings_for_k, encodings_for_v, mask = None):\n",
        "    # We pass these encodings to various weight matrices\n",
        "    q = self.W_q(encodings_for_q)\n",
        "    k = self.W_k(encodings_for_k)\n",
        "    v = self.W_v(encodings_for_v)\n",
        "\n",
        "    # Compute unscaled similarity scores ( q * k^T )\n",
        "    unscaled_similarity_scores = torch.mm(q, k.transpose(dim0 = self.row_dim, dim1 = self.col_dim))\n",
        "\n",
        "    # Scale the similarities by dividing by sqrt(k.col_dim)\n",
        "    scaled_similarity_scores = unscaled_similarity_scores / torch.sqrt(torch.tensor(k.size(self.col_dim)))\n",
        "\n",
        "    if mask is not None:\n",
        "      # Here we are masking out things we don't want to pay attention to\n",
        "      # We replace values we wanted masked out with a very small negative number so that the SoftMax() function\n",
        "      # will give all masked elements an output value (or \"probability\") of 0.\n",
        "      scaled_similarity_scores = scaled_similarity_scores.masked_fill(mask=mask, value=-1e9) # I've also seen -1e20 and -9e15 used in masking\n",
        "\n",
        "    # Apply softmax to determine what percent of each tokens' value to use in the final attention values.\n",
        "    attention_percents = F.softmax(scaled_similarity_scores, dim = self.col_dim)\n",
        "\n",
        "    # Scale the values by their associated percentages and add them up.\n",
        "    attention_scores = torch.matmul(attention_percents, v)\n",
        "\n",
        "    return attention_scores"
      ],
      "metadata": {
        "id": "xiqnfwbntG0r"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate Encoder-Decoder Attention"
      ],
      "metadata": {
        "id": "pNJ2mdlztY65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create matrices of token encodings...\n",
        "encodings_for_q = torch.tensor([[1.16, 0.23],\n",
        "                                [0.57, 1.36],\n",
        "                                [4.41, -2.16]])\n",
        "\n",
        "encodings_for_k = torch.tensor([[1.16, 0.23],\n",
        "                                [0.57, 1.36],\n",
        "                                [4.41, -2.16]])\n",
        "\n",
        "encodings_for_v = torch.tensor([[1.16, 0.23],\n",
        "                                [0.57, 1.36],\n",
        "                                [4.41, -2.16]])\n",
        "\n",
        "# Set manual seed to random number generator\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Create Attention object\n",
        "attention = Attention(d_model=2, row_dim=0, col_dim=1)\n",
        "\n",
        "# Calculate Encoder - Decoder Attention\n",
        "attention(encodings_for_q, encodings_for_k, encodings_for_v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDnLhnLJtYAc",
        "outputId": "5d950002-d37c-426d-b3ef-0043486b3bfa"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0100, 1.0641],\n",
              "        [0.2040, 0.7057],\n",
              "        [3.4989, 2.2427]], grad_fn=<MmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi-Head Attention"
      ],
      "metadata": {
        "id": "d9AxwEnRvSVI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code Multi-Head Attention"
      ],
      "metadata": {
        "id": "8uyaEKwNvZKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self,d_model = 2, row_dim = 0, col_dim = 1, num_heads = 1):\n",
        "    super().__init__()\n",
        "\n",
        "    # Initializes multiple independent attention heads and stores them in a ModuleList so they can be applied in parallel and properly managed by PyTorch\n",
        "    self.heads = nn.ModuleList([Attention(d_model, row_dim, col_dim) for _ in range(num_heads)])\n",
        "\n",
        "    self.col_dim = col_dim\n",
        "\n",
        "  def forward(self, encodings_q, encodings_for_k, encodings_for_v, mask = None):\n",
        "    # Run the data through all of the attention heads\n",
        "    return torch.cat([head(encodings_for_q, encodings_for_k, encodings_for_v) for head in self.heads], dim = self.col_dim)"
      ],
      "metadata": {
        "id": "YMaEDRiBuN6I"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate Multi-Head Attention"
      ],
      "metadata": {
        "id": "9zRjzyba5cuL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, verify that we can still correctly calculate attention with a single head..."
      ],
      "metadata": {
        "id": "56SH-azw5ifl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manual seed RNG\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Create multiHeadAttention object\n",
        "multiHeadAttention = MultiHeadAttention(d_model = 2, row_dim = 0, col_dim = 1, num_heads=1)\n",
        "\n",
        "# Calculate Encoder-Decoder Attention\n",
        "multiHeadAttention(encodings_for_q, encodings_for_k, encodings_for_v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0Bt5-MF5YdQ",
        "outputId": "421c1f50-ad4d-4e16-d585-d10090711581"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.0100, 1.0641],\n",
              "        [0.2040, 0.7057],\n",
              "        [3.4989, 2.2427]], grad_fn=<CatBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Second, calculate attention with multiple heads..."
      ],
      "metadata": {
        "id": "YwNx6iuy61J4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manual seed RNG\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Create multiHeadAttention object\n",
        "multiHeadAttention = MultiHeadAttention(d_model = 2, row_dim = 0, col_dim = 1, num_heads=3)\n",
        "\n",
        "# Calculate Multi-Head Attention\n",
        "multiHeadAttention(encodings_for_q, encodings_for_k, encodings_for_v)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZpv8S1b6ZJK",
        "outputId": "47f21bc3-283e-489b-aa12-4e85accaccdb"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.0100,  1.0641, -0.7081, -0.8268,  0.6226,  0.1312],\n",
              "        [ 0.2040,  0.7057, -0.7417, -0.9193,  0.5522,  0.2499],\n",
              "        [ 3.4989,  2.2427, -0.7190, -0.8447,  0.5669,  0.2324]],\n",
              "       grad_fn=<CatBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VpK1pVET7BdU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}